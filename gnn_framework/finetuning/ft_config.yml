# settings for executing the run
run_settings:
  num_t_workers: 2              # num of workers for the train set dataloader
  num_v_workers: 2              # num of workers for the validation set dataloader
  random_seed: 10               # fixed random seed

# settings that handle the io
io_settings:
  dataset_path:  'D:\Playground\windfarm-gnn\generated_graphs\train_set\OneWT'
  pretrained_model_dir: 'D:\Playground\windfarm-gnn\runs\GEN_4_layers_0.0_dropout_1e-3_lr_300_epochs_256_latent_dim_06_12_02_51' # path to the pretrained model
  model_version: 'best'          # choose from ['best', 'e{N}' where N is the epoch number]
  run_dir: './runs'             # path to the save directory for model saving
  save_epochs: 10               # number of epochs between model saves

# training hyperparameters
hyperparameters:
  epochs: 200                    # number of epochs
  train_ratio: 0.8               # ratio of the dataset to use for training
  start_lr: 5e-3                 # initial learning rate
  lr_decay_stop: 200             # decay the learning rate up until this epoch
  batch_size: 10                 # number of graphs per batch
  recompute_stats: True          # if the normalization stats should be recomputed

# model architecture settings
model_settings:
  ft_method: 'LoRA'              # choose from ['vanilla', 'LoRA', 'decoder', 'scratch']
